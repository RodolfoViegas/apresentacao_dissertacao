---
title: "Uma Análise Comparativa de Operadores de Combinação em *Ensembles* Heterogêneos para Previsão de Séries Temporais"

title-slide-attributes:
    data-background-image: ppgec_poli.png
    data-background-size: 20% 
    data-background-position: left 10% top 5%


lang: pt
date: 07/29/2025
date-format: DD/MM/YYYY

author:
  - name: Rodolfo Viegas de Albuquerque
    affiliation:
      - id: upe
        name: Universidade de Pernambuco

  - name: Prof. Dr. João Fausto Lorenzato de Oliveira
    affiliation: 
      - id: upe
bibliography: references.bib
format: 
  revealjs:
    logo: ppgec_logo.png
    css: style.css
    slide-number: true
    chalkboard: true


---


## Agenda

- Introdução
- Objetivos
- Fundamentação Teórica
- Metodologia
- Análise de Resultados
- Conclusão


# Introdução 

## Estudos de *Forecasting*
::: {.incremental}
* Crescimento da tomada de decisão baseada em dados;

* Previsão de séries temporais como ferramenta crucial;

* Limitações dos modelos individuais;

* Combinações de previsões como alternativa para ganho de acurácia;

* Fenômeno *forecast combination puzzle* e o dilema da complexidade.
:::

::: {.notes}
1- Governos, operadores do mercado, varegistas, todos se valem de previsões de séries temporais;

2- A literatura vem mostrando que a opção de combinar geralmente é a melhor forma de aumentar acuárcia. 

3 -A pesar desse fenômeno curioso, só podemos, então aplicar a média simples? Não há outras formas como mostraram os autores citados. 

:::

## Objetivo Geral

Analisar o desempenho de quatro combinares (média, mediana, operador proposto e SVR-stacking) para previsão de um passo à frente de séries temporais com sazonalidade mensal.

## Objetivos Específicos

::: {.incremental}
1. Comparar operadores (média, mediana, ponderada, *stacking*);

2. Avaliar impacto do número de modelos nas combinações;

3. Verificar robustez (desvio padrão) mediante o número de modelos adicionados;

4. Avaliar método baseado em *feature importance*.
:::


# Fundamentação Teórica

# Trabalhos Relacionados
::: {style="font-size: 85%;"}
1. Alguns trabalhos usando operadores **ponderados lineares** conseguiram vencer a médias simples, como @fforma, @kolassa2011, @fiorucci2020groec, @petropoulos2018bagging.
2. Com destaque para o trabalhos de @fforma que usou o XGBoost, que um ***ensemble* baseado em Árvores de Decisão**, como modelos para estimar os pesos;
3. O uso de FI é semelhante ao emprego dos coeficientes de regressão como pesos, mas há vantagens: **sem multicolinearidade** e **lida melhor que outras formas de distribuições**;
4. O modelo ET lida bem com **dados ruidosos** (@ghazwani2023computational);
5. E tem a **variância menor** que outros modelos como Random Forest @geurts2006extratrees.
:::
::: {.notes}
Alguns trabalhos importantes da áreas que usaram esses operadores

Falar um pouco deles
:::

## Séries Temporais

@box2015 definem séries temporais são definidas como uma sequência de observações feitas sequencialmente no tempo. 

* Discretas ou contínuas;
* Univariádas ou multivariádas.

Este trabalho limita-se ao uso de séries discretas e univariádas.

::: {.notes}
discretas ou contínuas em relação ao tempo
vetor ou matriz da séries
:::

## Combinações

* A literatura vem acumulando dados que mostram a eficiência no emprego de combinações (@clemen1989, @wang2023review)

* Uso de combinações corrige os problemas de estimação com modelos individuais, @makridakis_livro_1998;

* Com elas conseguimos nos aproximar da função real e desconhecida que representa os dados, @zhou2025.


## Tipos Básicos de Operadores

* De acordo com @kuncheva2014 há três tipos básicos de operadores de combinação:

:::: {.columns}

::: {.column}
### Tipos
1. Treináveis;
2. Não treináveis
3. Meta-modelos
:::

::: {.column}
### Usados no Trabalho
* Média Simples
* Mediana
* Média Ponderada
* *Stacking*
:::
::::


::: {.notes}
Falar dos modelos como pertencente a uma das classes
Falar que o stackin usa SVR como meta-modelo com kernel RBF, modleo não linear
:::

# Metodologia

## Metodo Proposto

- É uma combinação linear e estática (seus pesos não variam no tempo) por média ponderada para previsão de séries temporais para um passo à frente.

- Os pesos são estimados por meio da técnica de *feature importance* (FI) do modelo Extremely Randomized Trees (ET).


## *Feature Importance* 1
::: {style="font-size: 80%;"}
- FI é um técnica de interpretação de Árvores de Decisão e seus *ensembles*.

- Segundo @pml1Book, a medida de FI $R_k(T)$ de uma variável $k$ em uma Árvore de Decisão $T$ é expressa pela fórmula:

\begin{align}
    \label{eq:R}
    R_k(T) = \sum_{j=1}^{J-1} G_j \mathbb{I}(v_j = k)
\end{align}

- Esta formula, grosso modo, verifica se no nó $j$ existe a *feature* $k$, se sim, a função indicadora $\mathbb{I}$ retorna 1; senão, 0. Para multiplicar pelo ganho de informação $G_j$ do nó. 

- Os valores de ganho de informação de cada nó serão normalizado entre 0 e 1.
:::
## *Feature Importance* 2

- Para os *ensemble* calcula-se a média valores $R_k$ de cada feature $k$ para cada árvore $T_m$ da combinação $M$.

\begin{align}
		R_k = \frac{1}{M} \sum_{m=1}^{M} R_k(T_m)
\end{align}


## Extremely Randomized Trees (ET)


:::: {.columns style="font-size: 90%;"}
::: {.column width="50%"}

### Características

* É um ensemble de Árvore de Decisão sememlhante ao Random Forest;
* ET usa um amostra de colunas e com todas as linha;
* E, ao invés de verificar o valor ótimo que reduz a impureza de Gini/Entropia/MSE, escolhe aleatoriamente um valor limiar que represente a coluna.
:::
::: {.column width="50%"}

### Vantagens

* Mais rápida que os outros ensembles baseados em Árvore de Decisão;
* Lida bem com ruídos nos dados;
* Tem a variância mais baixa que o Random Forest.
:::
::::


## Treino e Teste 1

* Para avaliar os operadores foram usados 5 modelos estatísticos: ARIMA, ETS, CES, Theta e TBATS, e 4 de aprendizado de máquina: MLP, SVR, KNN e Random Forest;

* Os dados são 30 séries de sasonalidade mensal da Competição M3;

* As séries são divididas em conjunto de treino e teste com as últimas 18 observações de cada série compondo o conjunto teste;

* As métricas de avaliação usadas são RMSE e SMAPE.

::: {.notes}
Esses modelos foram escolhidos para analisar combinações heterogêneas, restringindo o escopo do trablho e seguindo a recomendação de diversidade;

As séries da M3 são muito usadas como benchmark e são mensais para restringir o escopo;

O número de observações do conjunto teste é seguindo a metodologia de Makridakis;

Foram escolhidas duas métricas para não eviesar a análise com somente um e SMAPE foi escolhida por causa dos problemas de MAPE.

:::


## Treino e Teste 2

![Diagrama de Treino e Teste](imagens/diagram.png)

## Treino e Teste 3

![algortimo para gerar Combinações](imagens/algo.png)

* Para cada uma das 30 séries, usando os 4 operadores, de 2 a 9 modelos, há 61.320 combinações.

\begin{align}
  C_j^{9} = \frac{9!}{j!(9-j)!}
\end{align}

## Ferramentas de Análise

1. Uso de agrupamento (*group by*) médio dos resultados RMSE e SMAPE em relação ao número de métodos na combinação;

2. Análise de Gráficos de Resultado Agrupado;

3. Box Plots;

4. Análise de Gráficos de Desvio Padrão Agrupado;

5. Diagrama de Distância Crítica.

# Resultados Individuais

## N1402 

::: {.panel-tabset}
### Série

![Série N1402 dividida em conjuntos de treino e de teste.](imagens/n1402.png)

### Tab. RMSE
::: {style="font-size: 80%;"}
|Nº Modelos  | Média    | Mediana  | Média Ponderada  | SVR-stacking* |
|------------|----------|----------|------------------|---------------|
|        2   | 1770,740 | 1770,740 | 1758,380         | 1791,461 |
|        3   | 1685,278 | 1790,400 | 1645,521         | 1745,400 |
|        4   | 1640,800 | 1739,003 | 1601,240         | 1717,897 |
|        5   | 1614,236 | 1780,500 | 1582,560         | 1708,140 |
|        6   | 1596,761 | 1743,203 | 1572,542         | 1705,821 |
|        7   | 1584,455 | 1782,866 | 1567,675         | 1705,115 |
|        8   | 1575,345 | 1747,335 | 1566,110         | 1705,056 |
|        9   | 1568,340 | 1849,635 | **1563,561**     | 1705,056 |
:::
### Gra. RMSE

![RMSE médio](imagens/rmse-n1402.png)

### Tab. SMAPE
::: {style="font-size: 80%;"}
|Nº Modelos | Média  | Mediana | Média Ponderada | SVR-stacking* |
|-----------|--------|---------|-----------------|---------------|
|        2  | 70,361 | 70,361  | 69,880          | 70,248 |
|        3  | 66,707 | 69,134  | 65,004          | 69,869 |
|        4  | 65,440 | 69,031  | 63,616          | 69,465 |
|        5  | 65,097 | 69,554  | 63,223          | 69,267 |
|        6  | 64,965 | 69,733  | 62,992          | 69,211 |
|        7  | 64,918 | 70,447  | **62,914**      | 69,194 |
|        8  | 64,902 | 70,631  | 62,980          | 69,192 |
|        9  | 64,989 | 72,686  | 63,084          | 69,192 |
:::
### Gra. SMAPE

![SMAPE médio](imagens/smape-n1402.png)
:::


## N1411 

::: {.panel-tabset}
### Série

![Série N1411 dividida em conjuntos de treino e de teste.](imagens/n1411.png)

### Tab. RMSE
::: {style="font-size: 80%;"}
|Nº Modelos  | Média   | Mediana | Média Ponderada | SVR-*stacking* |
|------------|---------|---------|-----------------|----------------|
|        2   | 800,525 | 800,525 | 801,864         | 851,850 |
|        3   | 782,224 | 841,570 | 784,939         | 849,847 |
|        4   | 773,135 | 819,003 | 777,042         | 849,366 |
|        5   | 767,718 | 842,212 | 769,271         | 849,298 |
|        6   | 764,128 | 828,168 | 764,043         | 849,256 |
|        7   | 761,578 | 842,194 | 756,919         | 849,256 |
|        8   | 759,675 | 833,516 | **743,206**     | 849,256 |
|        9   | 758,201 | 853,638 | 748,593         | 849,256 |

:::

### Gra. RMSE

![RMSE médio](imagens/rmse-n1411.png)

### Tab. SMAPE
::: {style="font-size: 80%;"}

|Nº Modelos | Média  | Mediana | Média Ponderada | SVR-*stacking* |
|-----------|--------|---------|-----------------|----------------|
|        2  | 15,625 | 15,625  | 15,518          | 16,628 |
|        3  | 15,257 | 16,383  | 15,147          | 16,636 |
|        4  | 15,061 | 15,947  | 14,970          | 16,630 |
|        5  | 14,931 | 16,482  | 14,806          | 16,630 |
|        6  | 14,857 | 16,214  | 14,721          | 16,629 |
|        7  | 14,813 | 16,592  | 14,597          | 16,629 |
|        8  | 14,807 | 16,452  | **14,350**      | 16,629 |
|        9  | 14,771 | 16,666  | 14,525          | 16,629 |
:::

### Gra. SMAPE

![SMAPE médio](imagens/smape-n1411.png)

:::



## N1501 

::: {.panel-tabset}
### Série

![Série N1411 dividida em conjuntos de treino e de teste.](imagens/n1501.png)

### Tab. RMSE
::: {style="font-size: 80%;"}
|Nº Modelos | Média      | Mediana | Média Ponderada | SVR-*stacking* |
|-----------|------------|---------|-----------------|----------------|
|        2  | 600,972    | 600,972 | 605,266         | 1415,820 |
|        3  | 594,697    | 606,104 | 600,605         | 1456,629 |
|        4  | 591,537    | 598,172 | 598,475         | 1458,460 |
|        5  | 589,631    | 602,214 | 597,284         | 1458,790 |
|        6  | 588,356    | 596,830 | 596,909         | 1458,790 |
|        7  | 587,443    | 601,875 | 596,241         | 1458,790 |
|        8  | 586,756    | 596,758 | 595,761         | 1458,790 |
|        9  | **586,221**| 597,759 | 594,568         | 1458,790 |
:::

### Gra. RMSE
::: {#fig-RMSE-n1501 layout-ncol=2}
![RMSE com SVR-stacking](imagens/rmse-n1501-1.png){#fig-rmse-n1501-com-stack}

![RMSE sem SVR-stacking](imagens/rmse-n1501-2.png){#fig-rmse-n1501-sem-stack}
:::


### Tab. SMAPE
::: {style="font-size: 80%;"}
|Nº Modelos | Média     | Mediana | Média Ponderada | SVR-*stacking* |
|-----------|-----------|---------|-----------------|----------------|
|        2  | 9,218     | 9,218   | 9,294           | 21,901 |
|        3  | 9,110     | 9,322   | 9,211           | 22,558 |
|        4  | 9,065     | 9,212   | 9,182           | 22,590 |
|        5  | 9,048     | 9,294   | 9,166           | 22,595 |
|        6  | 9,037     | 9,214   | 9,161           | 22,595 |
|        7  | 9,030     | 9,287   | 9,145           | 22,595 |
|        8  | 9,021     | 9,201   | 9,145           | 22,595 |
|        9  | **9,018** | 9,272   | 9,116           | 22,595 |
:::

### Gra. SMAPE

::: {#fig-SMAPE-n1501 layout-ncol=2}
![SMAPE com SVR-stacking](imagens/smape-n1501-1.png){#fig-rmse-n1501-com-stack}

![SMAPE sem SVR-stacking](imagens/smape-n1501-2.png){#fig-rmse-n1501-sem-stack}
:::

:::


## N2401 

::: {.panel-tabset}
### Série

![Série N2401 dividida em conjuntos de treino e de teste.](imagens/n2401.png)

### Tab. RMSE
::: {style="font-size: 80%;"}
|Nº Modelos | Média  | Mediana | Média Ponderada | SVR-*stacking* |
|-----------|--------|---------|-----------------|----------------|
|        2  | 58,217 | 58,217  | 54,118          | 587,052 |
|        3  | 57,256 | 63,578  | 51,954          | 606,876 |
|        4  | 56,847 | 62,025  | 50,948          | 611,767 |
|        5  | 56,629 | 66,172  | 49,706          | 613,702 |
|        6  | 56,495 | 64,995  | 49,470          | 615,034 |
|        7  | 56,404 | 70,032  | 49,628          | 616,250 |
|        8  | 56,339 | 68,962  | 47,773          | 617,420 |
|        9  | 56,290 | 81,506  | **45,278**      | 618,500 |
:::

### Gra. RMSE

::: {#fig-RMSE-n2401 layout-ncol=2}
![RMSE com SVR-stacking](imagens/rmse-n2401-1.png){#fig-rmse-n2401-com-stack}

![RMSE sem SVR-stacking](imagens/rmse-n2401-2.png){#fig-rmse-n2401-sem-stack}
:::


### Tab. SMAPE
::: {style="font-size: 80%;"}
|Nº Modelos | Média | Mediana | Média Ponderada | SVR-*stacking* |
|-----------|-------|---------|-----------------|----------------|
|        2  | 1,093 | 1,093   | 1,005           | 13,441 |
|        3  | 1,077 | 1,181   | 0,972           | 13,964 |
|        4  | 1,070 | 1,162   | 0,956           | 14,097 |
|        5  | 1,067 | 1,230   | 0,935           | 14,148 |
|        6  | 1,065 | 1,219   | 0,932           | 14,182 |
|        7  | 1,063 | 1,303   | 0,936           | 14,213 |
|        8  | 1,063 | 1,296   | 0,902           | 14,242 |
|        9  | 1,063 | 1,530   | **0,860**       | 14,269 |
:::

### Gra. SMAPE

::: {#fig-SMAPE-n2401 layout-ncol=2}
![SMAPE com SVR-stacking](imagens/smape-n2401-1.png){#fig-rmse-n2401-com-stack}

![SMAPE sem SVR-stacking](imagens/smape-n2401-2.png){#fig-rmse-n2401-sem-stack}
:::

:::

## N2402


::: {.panel-tabset}
### Série

![Série N2402 dividida em conjuntos de treino e de teste.](imagens/n2402.png)

### Tab. RMSE
::: {style="font-size: 80%;"}
|Nº Modelos | Média  | Mediana | Média Ponderada | SVR-stacking* |
|-----------|--------|---------|-----------------|---------------|
|        2  | 73,285 | 73,285  | 75,093          | 1085,426 |
|        3  | 69,580 | 72,588  | 69,935          | 1096,814 |
|        4  | 67,648 | 69,131  | 66,785          | 1101,889 |
|        5  | 66,475 | 70,630  | 65,053          | 1106,649 |
|        6  | 65,693 | 68,726  | 63,633          | 1111,671 |
|        7  | 65,135 | 71,785  | 63,073          | 1116,819 |
|        8  | 64,718 | 70,210  | 62,094          | 1124,255 |
|        9  | 64,396 | 77,586  | **61,848**      | 1128,511 |
:::

### Gra. RMSE
::: {#fig-RMSE-n2402 layout-ncol=2}
![RMSE com SVR-stacking](imagens/rmse-n2402-1.png){#fig-rmse-n2402-com-stack}

![RMSE sem SVR-stacking](imagens/rmse-n2402-2.png){#fig-rmse-n2402-sem-stack}
:::

### Tab. SMAPE
::: {style="font-size: 80%;"}
|Nº Modelos | Média | Mediana | Média Ponderada | SVR-*stacking* |
|-----------|-------|---------|-----------------|----------------|
|        2  | 0,876 | 0,876   | 0,888           | 17,568 |
|        3  | 0,848 | 0,856   | 0,844           | 17,785 |
|        4  | 0,830 | 0,819   | 0,815           | 17,875 |
|        5  | 0,817 | 0,835   | 0,795           | 17,960 |
|        6  | 0,807 | 0,813   | 0,777           | 18,049 |
|        7  | 0,796 | 0,854   | 0,769           | 18,140 |
|        8  | 0,789 | 0,833   | **0,753**       | 18,273 |
|        9  | 0,778 | 0,922   | 0,756           | 18,348 |
:::

### Gra. SMAPE
::: {#fig-SMAPE-n2402 layout-ncol=2}
![SMAPE com SVR-stacking](imagens/smape-n2402-1.png){#fig-rmse-n2402-com-stack}

![SMAPE sem SVR-stacking](imagens/smape-n2402-2.png){#fig-rmse-n2402-sem-stack}
:::

:::


# Resultado Geral

## Análise Geral Métrica RMSE
::: {.panel-tabset}

### Tabela RSME

::: {style="font-size: 80%;"}
| Nº Modelos | Média   | Mediana | Média Ponderada | SVR-*stacking*|
|------------|---------|---------|-----------------|---------------|
| 2          | 413,704 | 413,704 | 406,92          | 812,363 |
| 3          | 405,592 | 429,793 | 393,485         | 852,605 | 
| 4          | 401,542 | 420,327 | 385,919         | 868,687 |
| 5          | 399,143 | 433,941 | 380,714         | 874,316 |
| 6          | 397,564 | 427,107 | 376,198         | 877,221 |
| 7          | 396,448 | 442,518 | 372,836         | 878,519 |
| 8          | 395,619 | 436,335 | 370,042         | 879,328 |
| 9          | 394,979 | 472,767 | **367,276**     | 879,686 |
:::

### Gráfico RMSE

::: {#fig-RMSE layout-ncol=2}
![RMSE com SVR-stacking](imagens/mean-rmse-1.png){#fig-rmse-com-stack}

![RMSE sem SVR-stacking](imagens/mean-rmse-2.png){#fig-rmse-sem-stack}
:::

:::

## Análise Geral Métrica SMAPE
::: {.panel-tabset}

### Tabela SMAPE

::: {style="font-size: 80%;"}
|Nº Modelos | Média | Mediana | Média Ponderada | SVR-*stacking*|
|-----------|-------|---------|-----------------|---------------|        
|        2  | 7,998 | 7,998   | 7,863           | 15,177 |
|        3  | 7,792 | 8,217   | 7,535           | 16,007 |
|        4  | 7,712 | 8,087   | 7,380           | 16,358 |
|        5  | 7,678 | 8,317   | 7,284           | 16,494 |
|        6  | 7,661 | 8,230   | 7,202           | 16,568 |
|        7  | 7,649 | 8,497   | 7,142           | 16,603 |
|        8  | 7,644 | 8,418   | 7,090           | 16,625 |
|        9  | 7,640 | 9,023   | **7,051**       | 16,638 |
:::

### Gráfico SMAPE

::: {#fig-SMAPE layout-ncol=2}
![SMAPE com SVR-stacking](imagens/mean-smape-1.png){#fig-smape-com-stack}

![SMAPE sem SVR-stacking](imagens/mean-smape-2.png){#fig-smape-sem-stack}
:::

:::

# Box Plots e Análise de Dispersão

## Box Plots
::: {.panel-tabset}

### Box Plots RMSE

::: {#fig-box-plot-RMSE layout-ncol=2}
![RMSE com SVR-stacking](imagens/boxplot_rmse-1.png){#fig-rmse-box-plot-com-stack}

![RMSE sem SVR-stacking](imagens/boxplot_rmse-2.png){#fig-rmse-box-plot-sem-stack}
:::

### Box Plots SMAPE

::: {#fig-box-plot-SMAPE layout-ncol=2}
![SMAPE com SVR-stacking](imagens/boxplot_smape-1.png){#fig-smape-box-plot-com-stack}

![SMAPE sem SVR-stacking](imagens/boxplot_smape-2.png){#fig-smape-box-plot-sem-stack}
:::

:::

::: {.notes}
As distribuições dos modelos não são iguais, o que é indicativo de performance diferentes, com uns melhores que os outros.
:::

## Análise de Dispersão RMSE

::: {.panel-tabset}

### Tab. RMSE

::: {style="font-size: 80%;"}
|Nº Modelos | Média   | Mediana | Média Ponderada | SVR-*stacking*|
|-----------|---------|---------|-----------------|---------------|
|        2  | 376,211 | 376,211 | 378,640         | 416,214 |
|        3  | 359,513 | 389,573 | 355,494         | 395,833 |
|        4  | 350,819 | 372,831 | 345,208         | 384,150 |
|        5  | 345,454 | 383,874 | 339,261         | 379,478 |
|        6  | 341,820 | 371,095 | 335,090         | 378,087 |
|        7  | 339,256 | 380,699 | 332,040         | 377,647 |
|        8  | 337,709 | 369,024 | **330,675**     | 378,005 |
|        9  | 341,235 | 392,295 | 333,140         | 383,749 |
:::

### Gráf. RMSE

![Desvio Padrão RMSE](imagens/std-rmse.png){#fig-rmse-std-com-stack}

### Tab. SMAPE

::: {style="font-size: 80%;"}
|Nº Modelos | Média  | Mediana | Média Ponderada | SVR-*stacking*|
|-----------|--------|---------|-----------------|---------------|
|    2      | 12,789 | 12,789  | 13,022          | 12,529 |
|    3      | 12,161 | 12,669  | 11,872          | 12,164 |
|    4      | 11,937 | 12,563  | 11,596          | 11,956 |
|    5      | 11,859 | 12,677  | 11,490          | 11,868 |
|    6      | 11,820 | 12,645  | 11,424          | 11,834 |
|    7      | 11,801 | 12,771  | **11,390**      | 11,820 |
|    8      | 11,803 | 12,768  | 11,396          | 11,828 |
|    9      | 11,987 | 13,257  | 11,581          | 12,005 |
:::

### Gráf. SMAPE

![Desvio Padrão SMAPE](imagens/std-smape.png){#fig-smape-std-com-stack}

:::

## Distância Crítica

::: {#fig-DC layout-nrow=2}
![RMSE](imagens/cd-rmse.png){#fig-smape-dc}

![SMAPE](imagens/cd-smape.png){#fig-rmse-dc}
:::

::: {.notes}

O teste foi feito com 5% de nível significância mostrando claramente a diferença nos operadores.
:::

## Conclusão 1

1. Combinações superam modelos individuais;

2. Média ponderada com FI se destacou

3. A mediana não apresentou resultados satisfatórios;

4. O stacking obteve os piores resultados

5. Resultados mostram, no contexto do trabalho, que quanto mais modelos combinados, maior é a acurácia e a robutez para média simples e média ponderada;



::: {.notes}
1. fato corroborante com a literatura;
2. Dada as características da técnica de FI e do Extra Trees, ele consegue poderar os modelos na combinação.

3. Uma hipótese para isso é que os modelos da literatura foram homogêneos.O que pode indicar que a mediana funciona melhor para combinações homogêneas ou com baixa diversidade.

4. Uma possível explicação é que como SVR é um modelos não linear e determinítico, pode ter modelado o caos das séries. Kernel linear funcionou em Ribeiro e Coelho

5. Como os modelos são diferentes, é possível que a heterogênedade tenha contribuido
:::

## Conclusão 2

### Para trabalhos futuros

- Testar o combinador em séries com sazonalidades diferentes;
- Verificar se em previsão de muitos passos a performance continua satisfatória;
- Explorar outros *ensembles* de Árvores como estimador de pesos;
- Verificar a seleção de modelos por correlação dos resíduos;
- Aplicar os operador em sistemas híbridos.

## Referências